import streamlit as st
import pandas as pd
import json
import asyncio
import re
import unicodedata
from difflib import SequenceMatcher
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows
import io
import zipfile
from playwright.async_api import async_playwright
import time

# Seleniumã®ä»£æ›¿å®Ÿè£…
try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

# requests + BeautifulSoupã®ä»£æ›¿å®Ÿè£…
try:
    import requests
    from bs4 import BeautifulSoup
    import urllib.parse
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ€ JBAé¸æ‰‹ãƒ‡ãƒ¼ã‚¿ç…§åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰ˆï¼‰",
    page_icon="ğŸ€",
    layout="wide"
)

class RealtimeJBAVerificationSystem:
    def __init__(self):
        self.jba_data = {}
        self.session_data = None
        self._ensure_playwright_browsers()
    
    def _ensure_playwright_browsers(self):
        """Playwrightãƒ–ãƒ©ã‚¦ã‚¶ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
        try:
            import subprocess
            import sys
            import os
            
            st.info("ğŸ”§ Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’é–‹å§‹ã—ã¾ã™...")
            
            # 1. ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
            st.info("ğŸ“¦ ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
            deps_result = subprocess.run([sys.executable, "-m", "playwright", "install-deps", "chromium"], 
                                       capture_output=True, text=True, timeout=600)
            
            if deps_result.returncode == 0:
                st.success("âœ… ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
            else:
                st.warning("âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å•é¡ŒãŒã‚ã‚Šã¾ã—ãŸ")
            
            # 2. ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
            st.info("ğŸŒ Chromiumãƒ–ãƒ©ã‚¦ã‚¶ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
            browser_result = subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], 
                                          capture_output=True, text=True, timeout=600)
            
            if browser_result.returncode == 0:
                st.success("âœ… Playwrightãƒ–ãƒ©ã‚¦ã‚¶ãŒæ­£å¸¸ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸ")
            else:
                st.error("âŒ Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ")
                st.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {browser_result.stderr}")
                
        except Exception as e:
            st.error(f"âŒ Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.error("æ‰‹å‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™")
        
    async def login_to_jba(self, email, password):
        """JBAã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³"""
        # ã¾ãšPlaywrightã‚’è©¦ã™
        try:
            async with async_playwright() as p:
                # Streamlit Cloudå¯¾å¿œã®ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                browser = await p.chromium.launch(
                    headless=True,
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-accelerated-2d-canvas',
                        '--no-first-run',
                        '--no-zygote',
                        '--disable-gpu',
                        '--disable-web-security',
                        '--disable-features=VizDisplayCompositor',
                        '--disable-background-timer-throttling',
                        '--disable-backgrounding-occluded-windows',
                        '--disable-renderer-backgrounding'
                    ]
                )
                context = await browser.new_context()
                page = await context.new_page()

                # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
                await page.goto("https://team-jba.jp/login")
                await page.wait_for_load_state("networkidle")

                # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›ï¼ˆä¿®æ­£ç‰ˆï¼‰
                await page.fill('input[name="login_id"]', email)
                await page.fill('input[name="password"]', password)

                # ãƒ­ã‚°ã‚¤ãƒ³ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
                await page.click('button[type="submit"]')
                await page.wait_for_load_state("networkidle")

                # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸç¢ºèª
                if "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in await page.text_content("body"):
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
                    cookies = await context.cookies()
                    self.session_data = {
                        "cookies": cookies,
                        "user_agent": await page.evaluate("() => navigator.userAgent")
                    }
                    await browser.close()
                    return True
                else:
                    await browser.close()
                    return False

        except Exception as e:
            st.error(f"Playwrightãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.info("requests + BeautifulSoupã§ä»£æ›¿ãƒ­ã‚°ã‚¤ãƒ³ã‚’è©¦è¡Œä¸­...")
            
            # PlaywrightãŒå¤±æ•—ã—ãŸå ´åˆã€requests + BeautifulSoupã‚’è©¦ã™
            if REQUESTS_AVAILABLE:
                return self._login_with_requests(email, password)
            else:
                st.error("Playwrightãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå¿…è¦ã§ã™ã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
                return False
    
    def _login_with_requests(self, email, password):
        """requests + BeautifulSoupã‚’ä½¿ç”¨ã—ãŸJBAãƒ­ã‚°ã‚¤ãƒ³"""
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
            session = requests.Session()
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            })
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            login_page = session.get("https://team-jba.jp/login")
            soup = BeautifulSoup(login_page.content, 'html.parser')
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¢ã™ï¼ˆã‚µã‚¤ãƒˆã®æ§‹é€ ã«å¿œã˜ã¦èª¿æ•´ãŒå¿…è¦ï¼‰
            csrf_token = ""
            csrf_input = soup.find('input', {'name': '_token'}) or soup.find('input', {'name': 'csrf_token'})
            if csrf_input:
                csrf_token = csrf_input.get('value', '')
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            login_data = {
                'login_id': email,
                'password': password
            }
            if csrf_token:
                login_data['_token'] = csrf_token
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            login_response = session.post("https://team-jba.jp/login", data=login_data)
            
            # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸç¢ºèª
            if "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in login_response.text or "ãƒã‚¤ãƒšãƒ¼ã‚¸" in login_response.text:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
                self.session_data = {
                    "session": session,
                    "cookies": session.cookies.get_dict(),
                    "user_agent": session.headers.get('User-Agent', '')
                }
                st.success("âœ… requests + BeautifulSoupã§ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
                return True
            else:
                st.error("ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚èªè¨¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return False
                
        except Exception as e:
            st.error(f"requestsãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _login_with_selenium(self, email, password):
        """Seleniumã‚’ä½¿ç”¨ã—ãŸJBAãƒ­ã‚°ã‚¤ãƒ³"""
        try:
            # Chromeã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®š
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-web-security')
            chrome_options.add_argument('--disable-features=VizDisplayCompositor')
            
            # WebDriverã‚’åˆæœŸåŒ–
            driver = webdriver.Chrome(options=chrome_options)
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            driver.get("https://team-jba.jp/login")
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã«å…¥åŠ›
            email_input = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.NAME, "login_id"))
            )
            email_input.send_keys(email)
            
            password_input = driver.find_element(By.NAME, "password")
            password_input.send_keys(password)
            
            # ãƒ­ã‚°ã‚¤ãƒ³ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            submit_button = driver.find_element(By.CSS_SELECTOR, 'button[type="submit"]')
            submit_button.click()
            
            # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸç¢ºèª
            WebDriverWait(driver, 10).until(
                lambda d: "ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ" in d.page_source
            )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
            cookies = driver.get_cookies()
            self.session_data = {
                "cookies": cookies,
                "user_agent": driver.execute_script("return navigator.userAgent;")
            }
            
            driver.quit()
            st.success("âœ… Seleniumã§ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
            return True
            
        except Exception as e:
            st.error(f"Seleniumãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    async def search_team_by_university(self, university_name):
        """å¤§å­¦åã§ãƒãƒ¼ãƒ ã‚’æ¤œç´¢"""
        try:
            async with async_playwright() as p:
                # Streamlit Cloudå¯¾å¿œã®ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                browser = await p.chromium.launch(
                    headless=True,
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-accelerated-2d-canvas',
                        '--no-first-run',
                        '--no-zygote',
                        '--disable-gpu',
                        '--disable-web-security',
                        '--disable-features=VizDisplayCompositor',
                        '--disable-background-timer-throttling',
                        '--disable-backgrounding-occluded-windows',
                        '--disable-renderer-backgrounding'
                    ]
                )
                context = await browser.new_context()
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å¾©å…ƒ
                if self.session_data:
                    await context.add_cookies(self.session_data["cookies"])
                
                page = await context.new_page()
                
                # ğŸ” ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‚å—æ©Ÿèƒ½ã‚’è¿½åŠ 
                # é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ã‚‚æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                if st.checkbox("ğŸ”§ é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰", value=False):
                    context = await browser.new_context(devtools=True)
                    page = await context.new_page()
                st.info("ğŸ” æ¤œç´¢æ™‚ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç›£è¦–ä¸­...")
                request_logs = []
                response_logs = []
                
                # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‚å—
                page.on("request", lambda request: request_logs.append({
                    "method": request.method,
                    "url": request.url,
                    "headers": request.headers,
                    "post_data": request.post_data
                }))
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‚å—
                page.on("response", lambda response: response_logs.append({
                    "status": response.status,
                    "url": response.url,
                    "headers": response.headers
                }))
                
                # ãƒãƒ¼ãƒ æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
                await page.goto("https://team-jba.jp/organization/15250600/team/search")
                await page.wait_for_load_state("networkidle")
                
                # æ¤œç´¢æ¡ä»¶ã‚’è¨­å®š
                # å¹´åº¦: 2025
                await page.select_option('select[name="fiscal_year"]', "2025")
                await page.dispatch_event('select[name="fiscal_year"]', 'change')

                # æ€§åˆ¥: ç”·å­ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
                await page.check('input[name="team_gender_id[]"][value="1"]')

                # æ¤œç´¢ç¯„å›²ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã¾ã¾ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰
                
                # ãƒãƒ¼ãƒ åã§æ¤œç´¢
                await page.fill('input[name="team_name"]', university_name)
                
                # æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
                await page.click('#w2ui-search-button')
                await page.wait_for_timeout(3000)
                
                # æ¤œç´¢çµæœã‚’å–å¾—
                team_links = await page.query_selector_all('table tbody tr td a')
                team_urls = []
                
                for link in team_links:
                    href = await link.get_attribute('href')
                    if href and university_name in await link.text_content():
                        team_urls.append(href)
                
                await browser.close()
                
                # ğŸ” ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º
                st.subheader("ğŸ” æ¤œç´¢æ™‚ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°")
                
                if request_logs:
                    st.write("**ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸€è¦§:**")
                    for i, req in enumerate(request_logs):
                        with st.expander(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆ {i+1}: {req['method']} {req['url']}"):
                            st.json(req)
                else:
                    st.info("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒè¨˜éŒ²ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                
                if response_logs:
                    st.write("**ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¸€è¦§:**")
                    for i, res in enumerate(response_logs):
                        with st.expander(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ {i+1}: {res['status']} {res['url']}"):
                            st.json(res)
                else:
                    st.info("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¨˜éŒ²ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                
                # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å€™è£œã‚’ç‰¹å®š
                api_candidates = []
                for req in request_logs:
                    if req['method'] == 'POST' and ('search' in req['url'].lower() or 'api' in req['url'].lower()):
                        api_candidates.append(req)
                
                if api_candidates:
                    st.success("ğŸ¯ APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å€™è£œã‚’ç™ºè¦‹ã—ã¾ã—ãŸï¼")
                    for candidate in api_candidates:
                        st.write(f"**å€™è£œ:** {candidate['method']} {candidate['url']}")
                        if candidate['post_data']:
                            st.write(f"**POSTãƒ‡ãƒ¼ã‚¿:** {candidate['post_data']}")
                else:
                    st.warning("âš ï¸ APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
                return team_urls
                
        except Exception as e:
            st.error(f"ãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _search_team_with_selenium(self, university_name):
        """Seleniumã‚’ä½¿ç”¨ã—ãŸãƒãƒ¼ãƒ æ¤œç´¢"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            
            driver = webdriver.Chrome(options=chrome_options)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å¾©å…ƒ
            if self.session_data and "cookies" in self.session_data:
                driver.get("https://team-jba.jp")
                for cookie in self.session_data["cookies"]:
                    driver.add_cookie(cookie)
            
            # ãƒãƒ¼ãƒ æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            driver.get("https://team-jba.jp/organization/15250600/team/search")
            
            # æ¤œç´¢æ¡ä»¶ã‚’è¨­å®š
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.NAME, "fiscal_year"))
            )
            
            # å¹´åº¦: 2025
            fiscal_year_select = driver.find_element(By.NAME, "fiscal_year")
            fiscal_year_select.send_keys("2025")
            
            # æ€§åˆ¥: ç”·å­ï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
            gender_checkbox = driver.find_element(By.CSS_SELECTOR, 'input[name="team_gender_id[]"][value="1"]')
            gender_checkbox.click()
            
            # ãƒãƒ¼ãƒ åã§æ¤œç´¢
            team_name_input = driver.find_element(By.NAME, "team_name")
            team_name_input.send_keys(university_name)
            
            # æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
            search_button = driver.find_element(By.ID, "w2ui-search-button")
            search_button.click()
            
            # æ¤œç´¢çµæœã‚’å¾…æ©Ÿ
            time.sleep(3)
            
            # æ¤œç´¢çµæœã‚’å–å¾—
            team_links = driver.find_elements(By.CSS_SELECTOR, 'table tbody tr td a')
            team_urls = []
            
            for link in team_links:
                href = link.get_attribute('href')
                text = link.text
                if href and university_name in text:
                    team_urls.append(href)
            
            driver.quit()
            return team_urls
            
        except Exception as e:
            st.error(f"Seleniumãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _search_team_with_requests(self, university_name):
        """requests + BeautifulSoupã‚’ä½¿ç”¨ã—ãŸãƒãƒ¼ãƒ æ¤œç´¢"""
        try:
            if not self.session_data or "session" not in self.session_data:
                st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
                return []
            
            session = self.session_data["session"]
            
            # ãƒãƒ¼ãƒ æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            search_url = "https://team-jba.jp/organization/15250600/team/search"
            search_page = session.get(search_url)
            soup = BeautifulSoup(search_page.content, 'html.parser')
            
            # æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            search_data = {
                'fiscal_year': '2025',
                'team_gender_id[]': '1',  # ç”·å­
                'team_name': university_name
            }
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¢ã™
            csrf_input = soup.find('input', {'name': '_token'}) or soup.find('input', {'name': 'csrf_token'})
            if csrf_input:
                search_data['_token'] = csrf_input.get('value', '')
            
            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            search_response = session.post(search_url, data=search_data)
            search_soup = BeautifulSoup(search_response.content, 'html.parser')
            
            # æ¤œç´¢çµæœã‹ã‚‰ãƒãƒ¼ãƒ ãƒªãƒ³ã‚¯ã‚’å–å¾—
            team_links = search_soup.find_all('a', href=True)
            team_urls = []
            
            for link in team_links:
                href = link.get('href')
                text = link.get_text(strip=True)
                if href and university_name in text and '/team/' in href:
                    team_urls.append(href)
            
            return team_urls
            
        except Exception as e:
            st.error(f"requestsãƒãƒ¼ãƒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _search_team_with_api(self, university_name, api_endpoint=None):
        """APIã‚’ä½¿ç”¨ã—ãŸãƒãƒ¼ãƒ æ¤œç´¢ï¼ˆæ–°æ©Ÿèƒ½ï¼‰"""
        try:
            if not self.session_data or "session" not in self.session_data:
                st.error("ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
                return []
            
            session = self.session_data["session"]
            
            # APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ¤œç´¢URLã‚’ä½¿ç”¨
            if not api_endpoint:
                api_endpoint = "https://team-jba.jp/organization/15250600/team/search"
            
            # æ¤œç´¢ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
            search_data = {
                'fiscal_year': '2025',
                'team_gender_id[]': '1',  # ç”·å­
                'team_name': university_name
            }
            
            # CSRFãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¢ã™ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            try:
                search_page = session.get(api_endpoint)
                soup = BeautifulSoup(search_page.content, 'html.parser')
                csrf_input = soup.find('input', {'name': '_token'}) or soup.find('input', {'name': 'csrf_token'})
                if csrf_input:
                    search_data['_token'] = csrf_input.get('value', '')
            except:
                pass
            
            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
            st.info(f"ğŸ” APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­: {api_endpoint}")
            search_response = session.post(api_endpoint, data=search_data)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å½¢å¼ã‚’åˆ¤å®š
            content_type = search_response.headers.get('content-type', '')
            
            if 'application/json' in content_type:
                # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆ
                search_results = search_response.json()
                st.success("âœ… JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
                
                # JSONã‹ã‚‰ãƒãƒ¼ãƒ URLã‚’æŠ½å‡ºï¼ˆæ§‹é€ ã«å¿œã˜ã¦èª¿æ•´ãŒå¿…è¦ï¼‰
                team_urls = []
                if 'teams' in search_results:
                    for team in search_results['teams']:
                        if 'url' in team:
                            team_urls.append(team['url'])
                elif 'data' in search_results:
                    for team in search_results['data']:
                        if 'team_url' in team:
                            team_urls.append(team['team_url'])
                
                return team_urls
                
            else:
                # HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆï¼ˆå¾“æ¥ã®æ–¹æ³•ï¼‰
                st.info("ğŸ“„ HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
                search_soup = BeautifulSoup(search_response.content, 'html.parser')
                
                # æ¤œç´¢çµæœã‹ã‚‰ãƒãƒ¼ãƒ ãƒªãƒ³ã‚¯ã‚’å–å¾—
                team_links = search_soup.find_all('a', href=True)
                team_urls = []
                
                for link in team_links:
                    href = link.get('href')
                    text = link.get_text(strip=True)
                    if href and university_name in text and '/team/' in href:
                        team_urls.append(href)
                
                return team_urls
            
        except Exception as e:
            st.error(f"APIæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    async def get_team_members(self, team_url):
        """ãƒãƒ¼ãƒ ã®é¸æ‰‹ãƒ»ã‚¹ã‚¿ãƒƒãƒ•æƒ…å ±ã‚’å–å¾—"""
        try:
            async with async_playwright() as p:
                # Streamlit Cloudå¯¾å¿œã®ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                browser = await p.chromium.launch(
                    headless=True,
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-accelerated-2d-canvas',
                        '--no-first-run',
                        '--no-zygote',
                        '--disable-gpu',
                        '--disable-web-security',
                        '--disable-features=VizDisplayCompositor',
                        '--disable-background-timer-throttling',
                        '--disable-backgrounding-occluded-windows',
                        '--disable-renderer-backgrounding'
                    ]
                )
                context = await browser.new_context()
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å¾©å…ƒ
                if self.session_data:
                    await context.add_cookies(self.session_data["cookies"])
                
                page = await context.new_page()
                
                # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
                await page.goto(team_url)
                await page.wait_for_load_state("networkidle")
                
                # ãƒãƒ¼ãƒ åã‚’å–å¾—
                team_name_element = await page.query_selector('h1, h2, .team-name')
                team_name = await team_name_element.text_content() if team_name_element else "Unknown Team"
                
                # ãƒ¡ãƒ³ãƒãƒ¼ãƒªã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å¾…æ©Ÿ
                await page.wait_for_selector('#team-member-registration-list', timeout=10000)
                
                # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—
                member_rows = await page.query_selector_all('#team-member-registration-list tbody tr')
                members = []
                
                for row in member_rows:
                    cells = await row.query_selector_all('td')
                    if len(cells) >= 5:
                        member_id = await cells[0].text_content()
                        name_element = await cells[1].query_selector('a')
                        name = await name_element.text_content() if name_element else await cells[1].text_content()
                        birth_date = await cells[2].text_content()
                        origin = await cells[3].text_content()
                        division = await cells[4].text_content()
                        status = await cells[5].text_content() if len(cells) > 5 else ""
                        
                        members.append({
                            "member_id": member_id.strip(),
                            "name": name.strip(),
                            "birth_date": birth_date.strip(),
                            "origin": origin.strip(),
                            "division": division.strip(),
                            "status": status.strip(),
                            "type": "player" if "é¸æ‰‹" in division else "staff"
                        })
                
                await browser.close()
                return {
                    "team_name": team_name.strip(),
                    "team_url": team_url,
                    "members": members
                }
                
        except Exception as e:
            st.error(f"ãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"team_name": "Error", "team_url": team_url, "members": []}
    
    def _get_team_members_with_selenium(self, team_url):
        """Seleniumã‚’ä½¿ç”¨ã—ãŸãƒ¡ãƒ³ãƒãƒ¼å–å¾—"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            
            driver = webdriver.Chrome(options=chrome_options)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å¾©å…ƒ
            if self.session_data and "cookies" in self.session_data:
                driver.get("https://team-jba.jp")
                for cookie in self.session_data["cookies"]:
                    driver.add_cookie(cookie)
            
            # ãƒãƒ¼ãƒ è©³ç´°ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹
            driver.get(team_url)
            
            # ãƒãƒ¼ãƒ åã‚’å–å¾—
            team_name_elements = driver.find_elements(By.CSS_SELECTOR, 'h1, h2, .team-name')
            team_name = team_name_elements[0].text if team_name_elements else "Unknown Team"
            
            # ãƒ¡ãƒ³ãƒãƒ¼ãƒªã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å¾…æ©Ÿ
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.ID, "team-member-registration-list"))
            )
            
            # ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—
            member_rows = driver.find_elements(By.CSS_SELECTOR, '#team-member-registration-list tbody tr')
            members = []
            
            for row in member_rows:
                cells = row.find_elements(By.TAG_NAME, 'td')
                if len(cells) >= 5:
                    member_id = cells[0].text
                    name_element = cells[1].find_elements(By.TAG_NAME, 'a')
                    name = name_element[0].text if name_element else cells[1].text
                    birth_date = cells[2].text
                    origin = cells[3].text
                    division = cells[4].text
                    status = cells[5].text if len(cells) > 5 else ""
                    
                    members.append({
                        "member_id": member_id.strip(),
                        "name": name.strip(),
                        "birth_date": birth_date.strip(),
                        "origin": origin.strip(),
                        "division": division.strip(),
                        "status": status.strip(),
                        "type": "player" if "é¸æ‰‹" in division else "staff"
                    })
            
            driver.quit()
            return {
                "team_name": team_name.strip(),
                "team_url": team_url,
                "members": members
            }
            
        except Exception as e:
            st.error(f"Seleniumãƒ¡ãƒ³ãƒãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"team_name": "Error", "team_url": team_url, "members": []}
    
    async def get_university_data(self, university_name):
        """å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        st.info(f"ğŸ” {university_name}ã®ãƒãƒ¼ãƒ ã‚’æ¤œç´¢ä¸­...")
        
        # ãƒãƒ¼ãƒ ã‚’æ¤œç´¢
        team_urls = await self.search_team_by_university(university_name)
        
        if not team_urls:
            st.warning(f"âš ï¸ {university_name}ã®ãƒãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        st.info(f"ğŸ“Š {university_name}ã®é¸æ‰‹ãƒ»ã‚¹ã‚¿ãƒƒãƒ•æƒ…å ±ã‚’å–å¾—ä¸­...")
        
        # å„ãƒãƒ¼ãƒ ã®ãƒ¡ãƒ³ãƒãƒ¼æƒ…å ±ã‚’å–å¾—
        all_members = []
        for i, team_url in enumerate(team_urls):
            with st.spinner(f"ãƒãƒ¼ãƒ  {i+1}/{len(team_urls)} ã‚’å‡¦ç†ä¸­..."):
                team_data = await self.get_team_members(team_url)
                if team_data and team_data["members"]:
                    all_members.extend(team_data["members"])
        
        return {
            "university_name": university_name,
            "members": all_members
        }
    
    def normalize_name(self, name):
        """åå‰ã®æ­£è¦åŒ–"""
        if not name or pd.isna(name):
            return ""
        
        name = str(name)
        
        # 1. å…¨è§’ãƒ»åŠè§’çµ±ä¸€
        name = unicodedata.normalize('NFKC', name)
        
        # 2. è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®æ­£è¦åŒ–ï¼ˆå…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚‚å«ã‚€ï¼‰
        name = re.sub(r'[ãƒ»ï½¥ã€ï¼Œ,\.\sã€€]+', '', name)
        
        # 3. å¤§æ–‡å­—å°æ–‡å­—çµ±ä¸€
        name = name.lower()
        
        # 4. ã‚ˆãã‚ã‚‹è¡¨è¨˜æºã‚Œã®çµ±ä¸€
        name = re.sub(r'[ãƒ¼âˆ’â€â€”â€“]', '', name)  # é•·éŸ³ç¬¦ã€ãƒã‚¤ãƒ•ãƒ³ã€ã‚¨ãƒ ãƒ€ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒ³ãƒ€ãƒƒã‚·ãƒ¥é™¤å»
        
        return name
    
    def normalize_birth_date(self, birth_date):
        """ç”Ÿå¹´æœˆæ—¥ã®æ­£è¦åŒ–"""
        if not birth_date or pd.isna(birth_date):
            return ""
        
        birth_date = str(birth_date)
        
        # æ§˜ã€…ãªæ—¥ä»˜å½¢å¼ã«å¯¾å¿œ
        patterns = [
            r'(\d{4})[/\-å¹´](\d{1,2})[/\-æœˆ](\d{1,2})[æ—¥]?',
            r'(\d{4})[/\-](\d{1,2})[/\-](\d{1,2})',
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, birth_date)
            if match:
                year, month, day = match.groups()
                return f"{year}/{int(month):02d}/{int(day):02d}"
        
        return birth_date
    
    def calculate_ultimate_similarity(self, name1, name2):
        """ç©¶æ¥µã®é¡ä¼¼åº¦è¨ˆç®—"""
        if not name1 or not name2:
            return 0.0
        
        # æ­£è¦åŒ–
        norm_name1 = self.normalize_name(name1)
        norm_name2 = self.normalize_name(name2)
        
        if norm_name1 == norm_name2:
            return 1.0
        
        # 1. åŸºæœ¬çš„ãªé¡ä¼¼åº¦
        basic_similarity = SequenceMatcher(None, norm_name1, norm_name2).ratio()
        
        # 2. æ–‡å­—å˜ä½ã®é¡ä¼¼åº¦
        char_similarity = self.calculate_character_similarity(norm_name1, norm_name2)
        
        # 3. éƒ¨åˆ†æ–‡å­—åˆ—ã®é¡ä¼¼åº¦
        substring_similarity = self.calculate_substring_similarity(norm_name1, norm_name2)
        
        # 4. éŸ³å£°é¡ä¼¼åº¦
        phonetic_similarity = self.calculate_phonetic_similarity(name1, name2)
        
        # é‡ã¿ä»˜ãå¹³å‡
        ultimate_similarity = (
            basic_similarity * 0.4 +
            char_similarity * 0.3 +
            substring_similarity * 0.2 +
            phonetic_similarity * 0.1
        )
        
        return ultimate_similarity
    
    def calculate_character_similarity(self, name1, name2):
        """æ–‡å­—å˜ä½ã®é¡ä¼¼åº¦"""
        if not name1 or not name2:
            return 0.0
        
        chars1 = set(name1)
        chars2 = set(name2)
        
        common_chars = chars1.intersection(chars2)
        total_chars = chars1.union(chars2)
        
        if not total_chars:
            return 0.0
        
        return len(common_chars) / len(total_chars)
    
    def calculate_substring_similarity(self, name1, name2):
        """éƒ¨åˆ†æ–‡å­—åˆ—ã®é¡ä¼¼åº¦"""
        if not name1 or not name2:
            return 0.0
        
        max_ratio = 0.0
        
        # æ§˜ã€…ãªé•·ã•ã®éƒ¨åˆ†æ–‡å­—åˆ—ã‚’ãƒã‚§ãƒƒã‚¯
        for length in range(2, min(len(name1), len(name2)) + 1):
            for i in range(len(name1) - length + 1):
                substring = name1[i:i+length]
                if substring in name2:
                    ratio = length / max(len(name1), len(name2))
                    max_ratio = max(max_ratio, ratio)
        
        return max_ratio
    
    def calculate_phonetic_similarity(self, name1, name2):
        """éŸ³å£°é¡ä¼¼åº¦ï¼ˆã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠå¯¾å¿œï¼‰"""
        if not name1 or not name2:
            return 0.0
        
        # ã²ã‚‰ãŒãªã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›
        def to_katakana(text):
            return text.translate(str.maketrans('ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚’ã‚“', 'ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ²ãƒ³'))
        
        katakana1 = to_katakana(name1)
        katakana2 = to_katakana(name2)
        
        return SequenceMatcher(None, katakana1, katakana2).ratio()
    
    def calculate_raw_similarity(self, name1, name2):
        """å…ƒãƒ‡ãƒ¼ã‚¿ã®é¡ä¼¼åº¦è¨ˆç®—ï¼ˆæ­£è¦åŒ–ãªã—ï¼‰"""
        if not name1 or not name2:
            return 0.0
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ä¸€è‡´
        if name1 == name2:
            return 1.0
        
        # åŸºæœ¬çš„ãªé¡ä¼¼åº¦ï¼ˆæ­£è¦åŒ–ãªã—ï¼‰
        basic_similarity = SequenceMatcher(None, name1, name2).ratio()
        
        # æ–‡å­—å˜ä½ã®é¡ä¼¼åº¦ï¼ˆæ­£è¦åŒ–ãªã—ï¼‰
        char_similarity = self.calculate_character_similarity(name1, name2)
        
        # éƒ¨åˆ†æ–‡å­—åˆ—ã®é¡ä¼¼åº¦ï¼ˆæ­£è¦åŒ–ãªã—ï¼‰
        substring_similarity = self.calculate_substring_similarity(name1, name2)
        
        # é‡ã¿ä»˜ãå¹³å‡
        raw_similarity = (
            basic_similarity * 0.5 +
            char_similarity * 0.3 +
            substring_similarity * 0.2
        )
        
        return raw_similarity
    
    def detect_original_differences(self, name1, name2):
        """å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®é•ã„ã‚’æ¤œå‡º"""
        if not name1 or not name2:
            return []
        
        differences = []
        
        # 1. æ–‡å­—å˜ä½ã§ã®é•ã„ã‚’æ¤œå‡º
        for i, (char1, char2) in enumerate(zip(name1, name2)):
            if char1 != char2:
                differences.append(f"ä½ç½®{i+1}: '{char1}' â†’ '{char2}'")
        
        # 2. é•·ã•ã®é•ã„
        if len(name1) != len(name2):
            if len(name1) > len(name2):
                differences.append(f"ä½™åˆ†ãªæ–‡å­—: '{name1[len(name2):]}'")
            else:
                differences.append(f"ä¸è¶³æ–‡å­—: '{name2[len(name1):]}'")
        
        # 3. å…¨è§’ãƒ»åŠè§’ã®é•ã„
        norm1 = unicodedata.normalize('NFKC', name1)
        norm2 = unicodedata.normalize('NFKC', name2)
        if norm1 != norm2:
            differences.append("å…¨è§’ãƒ»åŠè§’ã®é•ã„")
        
        # 4. è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®é•ã„
        clean1 = re.sub(r'[ãƒ»ï½¥ã€ï¼Œ,\.\sã€€]+', '', name1)
        clean2 = re.sub(r'[ãƒ»ï½¥ã€ï¼Œ,\.\sã€€]+', '', name2)
        if clean1 != clean2:
            differences.append("è¨˜å·ãƒ»ã‚¹ãƒšãƒ¼ã‚¹ã®é•ã„")
        
        return differences
    
    def find_all_possible_matches(self, excel_row, university_data, threshold=0.3):
        """ã™ã¹ã¦ã®å¯èƒ½ãªãƒãƒƒãƒã‚’æ¤œç´¢ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ç›´æ¥æ¯”è¼ƒï¼‰"""
        if not university_data or not university_data.get("members"):
            return []
        
        excel_name = excel_row.get('é¸æ‰‹å', excel_row.get('åå‰', excel_row.get('æ°å', '')))
        excel_birth = excel_row.get('ç”Ÿå¹´æœˆæ—¥', excel_row.get('èª•ç”Ÿæ—¥', ''))
        excel_team = excel_row.get('ãƒãƒ¼ãƒ å', excel_row.get('æ‰€å±', ''))
        
        matches = []
        
        for member in university_data["members"]:
            # 1. å…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯ï¼ˆæ­£è¦åŒ–ãªã—ï¼‰
            exact_match = excel_name == member["name"]
            
            # 2. å…ƒãƒ‡ãƒ¼ã‚¿ã®é¡ä¼¼åº¦ï¼ˆæ­£è¦åŒ–ãªã—ï¼‰
            name_similarity = self.calculate_raw_similarity(excel_name, member["name"])
            
            # 3. å…ƒãƒ‡ãƒ¼ã‚¿ã®é•ã„ã‚’è©³ç´°æ¤œå‡º
            original_differences = self.detect_original_differences(excel_name, member["name"])
            
            # ç”Ÿå¹´æœˆæ—¥ã®ä¸€è‡´ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒï¼‰
            birth_match = False
            if excel_birth and member["birth_date"]:
                birth_match = excel_birth == member["birth_date"]
            
            # ãƒãƒ¼ãƒ åã®ä¸€è‡´ï¼ˆãƒœãƒ¼ãƒŠã‚¹ï¼‰
            team_bonus = 0.1 if excel_team and excel_team in member.get("team_name", "") else 0.0
            
            # ç”Ÿå¹´æœˆæ—¥ä¸€è‡´ãƒœãƒ¼ãƒŠã‚¹
            birth_bonus = 0.2 if birth_match else 0.0
            
            # æœ€çµ‚ã‚¹ã‚³ã‚¢ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ä¸€è‡´ã®ã¿1.0ï¼‰
            if exact_match:
                final_score = 1.0
            else:
                final_score = name_similarity + team_bonus + birth_bonus
            
            if final_score >= threshold:
                matches.append({
                    "member": member,
                    "exact_match": exact_match,
                    "name_similarity": name_similarity,
                    "original_differences": original_differences,
                    "birth_match": birth_match,
                    "team_bonus": team_bonus,
                    "birth_bonus": birth_bonus,
                    "final_score": final_score
                })
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        matches.sort(key=lambda x: x["final_score"], reverse=True)
        return matches[:5]  # ä¸Šä½5ä»¶ã¾ã§
    
    def verify_excel_data(self, df, university_data, threshold=0.3):
        """ã‚¨ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç…§åˆ"""
        results = []
        
        for index, row in df.iterrows():
            matches = self.find_all_possible_matches(row, university_data, threshold)
            
            if not matches:
                results.append({
                    "index": index,
                    "excel_row": row,
                    "status": "æœªãƒãƒƒãƒ",
                    "matches": [],
                    "best_match": None
                })
            elif len(matches) == 1 and matches[0]["final_score"] >= 1.00:
                results.append({
                    "index": index,
                    "excel_row": row,
                    "status": "ãƒãƒƒãƒ",
                    "matches": matches,
                    "best_match": matches[0]
                })
            else:
                results.append({
                    "index": index,
                    "excel_row": row,
                    "status": "è¤‡æ•°å€™è£œ",
                    "matches": matches,
                    "best_match": matches[0] if matches else None
                })
        
        return results
    
    def create_corrected_excel(self, df, results, university_name):
        """ä¿®æ­£ç‰ˆã‚¨ã‚¯ã‚»ãƒ«ã‚’ä½œæˆ"""
        # æ–°ã—ã„åˆ—ã‚’è¿½åŠ 
        df_copy = df.copy()
        df_copy['ç…§åˆçµæœ'] = ''
        df_copy['å…ƒãƒ‡ãƒ¼ã‚¿'] = ''
        df_copy['JBAæ­£è§£'] = ''
        df_copy['JBAæ­£è§£ç”Ÿå¹´æœˆæ—¥'] = ''
        df_copy['JBAæ­£è§£ãƒãƒ¼ãƒ å'] = ''
        df_copy['é¡ä¼¼åº¦'] = ''
        df_copy['ä¿®æ­£ææ¡ˆ'] = ''
        df_copy['è©³ç´°åˆ†æ'] = ''
        df_copy['äº›ç´°ãªé•ã„'] = ''
        
        for result in results:
            index = result["index"]
            status = result["status"]
            best_match = result["best_match"]
            
            df_copy.at[index, 'ç…§åˆçµæœ'] = status
            
            if best_match:
                member = best_match["member"]
                excel_name = df_copy.at[index, 'é¸æ‰‹å'] if 'é¸æ‰‹å' in df_copy.columns else df_copy.at[index, 'åå‰']
                excel_birth = df_copy.at[index, 'ç”Ÿå¹´æœˆæ—¥'] if 'ç”Ÿå¹´æœˆæ—¥' in df_copy.columns else df_copy.at[index, 'èª•ç”Ÿæ—¥']
                
                # å…ƒãƒ‡ãƒ¼ã‚¿ã¨JBAæ­£è§£ã‚’ä¸¦ã¹ã¦è¡¨ç¤º
                df_copy.at[index, 'å…ƒãƒ‡ãƒ¼ã‚¿'] = f"{excel_name} {excel_birth}"
                df_copy.at[index, 'JBAæ­£è§£'] = f"{member['name']} {member['birth_date']}"
                df_copy.at[index, 'JBAæ­£è§£ç”Ÿå¹´æœˆæ—¥'] = member["birth_date"]
                df_copy.at[index, 'JBAæ­£è§£ãƒãƒ¼ãƒ å'] = university_name
                df_copy.at[index, 'é¡ä¼¼åº¦'] = f"{best_match['final_score']:.3f}"
                
                # ä¿®æ­£ææ¡ˆ
                corrections = []
                if excel_name != member["name"]:
                    corrections.append(f"åå‰: {member['name']}")
                if excel_birth != member["birth_date"]:
                    corrections.append(f"ç”Ÿå¹´æœˆæ—¥: {member['birth_date']}")
                if not corrections:
                    corrections.append("ä¿®æ­£ä¸è¦")
                
                df_copy.at[index, 'ä¿®æ­£ææ¡ˆ'] = "; ".join(corrections)
                
                # è©³ç´°åˆ†æ
                analysis = []
                if best_match.get("exact_match"):
                    analysis.append("å®Œå…¨ä¸€è‡´")
                elif best_match["name_similarity"] < 1.0:
                    analysis.append(f"åå‰é¡ä¼¼åº¦: {best_match['name_similarity']:.3f}")
                if best_match["birth_match"]:
                    analysis.append("ç”Ÿå¹´æœˆæ—¥ä¸€è‡´")
                if best_match["team_bonus"] > 0:
                    analysis.append("ãƒãƒ¼ãƒ åä¸€è‡´")
                
                df_copy.at[index, 'è©³ç´°åˆ†æ'] = "; ".join(analysis)
                
                # å…ƒãƒ‡ãƒ¼ã‚¿ã®é•ã„ã‚’è©³ç´°è¡¨ç¤º
                if best_match.get("original_differences"):
                    df_copy.at[index, 'äº›ç´°ãªé•ã„'] = "; ".join(best_match["original_differences"])
                elif best_match["name_similarity"] < 1.0:
                    df_copy.at[index, 'äº›ç´°ãªé•ã„'] = f"å…ƒãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜ãŒç•°ãªã‚Šã¾ã™ï¼ˆé¡ä¼¼åº¦: {best_match['name_similarity']:.3f}ï¼‰"
            else:
                # JBAã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆ
                excel_name = df_copy.at[index, 'é¸æ‰‹å'] if 'é¸æ‰‹å' in df_copy.columns else df_copy.at[index, 'åå‰']
                excel_birth = df_copy.at[index, 'ç”Ÿå¹´æœˆæ—¥'] if 'ç”Ÿå¹´æœˆæ—¥' in df_copy.columns else df_copy.at[index, 'èª•ç”Ÿæ—¥']
                
                df_copy.at[index, 'å…ƒãƒ‡ãƒ¼ã‚¿'] = f"{excel_name} {excel_birth}"
                df_copy.at[index, 'JBAæ­£è§£'] = "JBAç™»éŒ²ãªã—"
                df_copy.at[index, 'ä¿®æ­£ææ¡ˆ'] = "JBAã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“"
                df_copy.at[index, 'è©³ç´°åˆ†æ'] = "è©²å½“ã™ã‚‹é¸æ‰‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        
        return df_copy

def main():
    st.title("ğŸ€ JBAé¸æ‰‹ãƒ‡ãƒ¼ã‚¿ç…§åˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç‰ˆï¼‰")
    st.markdown("**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§JBAã‚µã‚¤ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ç…§åˆã—ã¾ã™**")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    if 'verification_system' not in st.session_state:
        st.session_state.verification_system = RealtimeJBAVerificationSystem()
    
    system = st.session_state.verification_system
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("ğŸ” JBAãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±")
        email = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", type="default")
        password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
        
        st.header("âš™ï¸ è¨­å®š")
        threshold = st.slider("é¡ä¼¼åº¦é–¾å€¤", 0.1, 1.0, 1.00, 0.05, help="1.00æ¨å¥¨ï¼šå®Œå…¨ä¸€è‡´ã‚’æ±‚ã‚ã‚‹å ´åˆã«ä½¿ç”¨ã—ã¾ã™")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“„ ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«")
        uploaded_files = st.file_uploader(
            "ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯èƒ½ï¼‰",
            type=['xlsx', 'xls'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
            for file in uploaded_files:
                st.write(f"- {file.name}")
    
    with col2:
        st.header("ğŸ« å¤§å­¦å")
        university_input = st.text_area(
            "å¤§å­¦åã‚’å…¥åŠ›ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰",
            height=150,
            placeholder="ä¾‹:\nç™½é´å¤§å­¦\næ—©ç¨²ç”°å¤§å­¦\næ…¶æ‡‰å¤§å­¦"
        )
        
        if university_input:
            universities = [uni.strip() for uni in university_input.split('\n') if uni.strip()]
            st.success(f"âœ… {len(universities)}å€‹ã®å¤§å­¦ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸ")
            for uni in universities:
                st.write(f"- {uni}")
    
    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ç…§åˆã‚’å®Ÿè¡Œ", type="primary"):
        if not email or not password:
            st.error("âŒ JBAãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        if not uploaded_files:
            st.error("âŒ ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
            return
        
        if not university_input:
            st.error("âŒ å¤§å­¦åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        universities = [uni.strip() for uni in university_input.split('\n') if uni.strip()]
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # 1. ãƒ­ã‚°ã‚¤ãƒ³
            status_text.text("ğŸ” JBAã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")
            login_success = asyncio.run(system.login_to_jba(email, password))
            
            if not login_success:
                st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                return
            
            progress_bar.progress(20)
            st.success("âœ… ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
            
            # 2. å„å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            all_university_data = {}
            for i, university in enumerate(universities):
                status_text.text(f"ğŸ“Š {university}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... ({i+1}/{len(universities)})")
                
                university_data = asyncio.run(system.get_university_data(university))
                if university_data:
                    all_university_data[university] = university_data
                
                progress = 20 + (i + 1) * 60 / len(universities)
                progress_bar.progress(int(progress))
            
            # 3. å„ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            corrected_files = {}
            
            for file_index, uploaded_file in enumerate(uploaded_files):
                status_text.text(f"ğŸ” {uploaded_file.name}ã‚’å‡¦ç†ä¸­... ({file_index+1}/{len(uploaded_files)})")
                
                # ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                df = pd.read_excel(uploaded_file)
                
                # å„å¤§å­¦ã®ãƒ‡ãƒ¼ã‚¿ã¨ç…§åˆ
                all_results = []
                for university, university_data in all_university_data.items():
                    results = system.verify_excel_data(df, university_data, threshold)
                    all_results.extend(results)
                
                # ä¿®æ­£ç‰ˆã‚¨ã‚¯ã‚»ãƒ«ã‚’ä½œæˆ
                corrected_df = system.create_corrected_excel(df, all_results, ", ".join(universities))
                corrected_files[uploaded_file.name] = corrected_df
                
                progress = 80 + (file_index + 1) * 20 / len(uploaded_files)
                progress_bar.progress(int(progress))
            
            progress_bar.progress(100)
            status_text.text("âœ… å‡¦ç†å®Œäº†")
            
            # çµæœè¡¨ç¤º
            st.success("ğŸ‰ ãƒ‡ãƒ¼ã‚¿ç…§åˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            # çµæœã‚¿ãƒ–
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š çµ±è¨ˆ", "âœ… ãƒãƒƒãƒ", "âŒ æœªãƒãƒƒãƒ", "âš ï¸ è¤‡æ•°å€™è£œ"])
            
            with tab1:
                st.subheader("ğŸ“Š ç…§åˆçµæœçµ±è¨ˆ")
                
                total_records = sum(len(df) for df in corrected_files.values())
                matched_count = sum(1 for results in [system.verify_excel_data(df, uni_data, threshold) for df, uni_data in [(pd.read_excel(f), uni_data) for f in uploaded_files for uni_data in all_university_data.values()]] for result in results if result["status"] == "ãƒãƒƒãƒ")
                unmatched_count = sum(1 for results in [system.verify_excel_data(df, uni_data, threshold) for df, uni_data in [(pd.read_excel(f), uni_data) for f in uploaded_files for uni_data in all_university_data.values()]] for result in results if result["status"] == "æœªãƒãƒƒãƒ")
                multiple_count = sum(1 for results in [system.verify_excel_data(df, uni_data, threshold) for df, uni_data in [(pd.read_excel(f), uni_data) for f in uploaded_files for uni_data in all_university_data.values()]] for result in results if result["status"] == "è¤‡æ•°å€™è£œ")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ç·ä»¶æ•°", total_records)
                with col2:
                    st.metric("ãƒãƒƒãƒ", matched_count, f"{matched_count/total_records*100:.1f}%" if total_records > 0 else "0%")
                with col3:
                    st.metric("æœªãƒãƒƒãƒ", unmatched_count, f"{unmatched_count/total_records*100:.1f}%" if total_records > 0 else "0%")
                with col4:
                    st.metric("è¤‡æ•°å€™è£œ", multiple_count, f"{multiple_count/total_records*100:.1f}%" if total_records > 0 else "0%")
            
            with tab2:
                st.subheader("âœ… ãƒãƒƒãƒã—ãŸé¸æ‰‹")
                for file_name, df in corrected_files.items():
                    matched_df = df[df['ç…§åˆçµæœ'] == 'ãƒãƒƒãƒ']
                    if not matched_df.empty:
                        st.write(f"**{file_name}**")
                        st.dataframe(matched_df[['å…ƒãƒ‡ãƒ¼ã‚¿', 'JBAæ­£è§£', 'é¡ä¼¼åº¦', 'ä¿®æ­£ææ¡ˆ']])
            
            with tab3:
                st.subheader("âŒ æœªãƒãƒƒãƒã®é¸æ‰‹")
                for file_name, df in corrected_files.items():
                    unmatched_df = df[df['ç…§åˆçµæœ'] == 'æœªãƒãƒƒãƒ']
                    if not unmatched_df.empty:
                        st.write(f"**{file_name}**")
                        st.dataframe(unmatched_df[['å…ƒãƒ‡ãƒ¼ã‚¿', 'JBAæ­£è§£', 'è©³ç´°åˆ†æ']])
            
            with tab4:
                st.subheader("âš ï¸ è¤‡æ•°å€™è£œãŒã‚ã‚‹é¸æ‰‹")
                for file_name, df in corrected_files.items():
                    multiple_df = df[df['ç…§åˆçµæœ'] == 'è¤‡æ•°å€™è£œ']
                    if not multiple_df.empty:
                        st.write(f"**{file_name}**")
                        st.dataframe(multiple_df[['å…ƒãƒ‡ãƒ¼ã‚¿', 'JBAæ­£è§£', 'é¡ä¼¼åº¦', 'è©³ç´°åˆ†æ']])
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.subheader("ğŸ“¥ ä¿®æ­£ç‰ˆã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
                for file_name, df in corrected_files.items():
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿®æ­£
                    base_name = file_name.rsplit('.', 1)[0]
                    corrected_name = f"{base_name}_ä¿®æ­£ç‰ˆ.xlsx"
                    
                    # Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='ç…§åˆçµæœ')
                        
                        # ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’å–å¾—ã—ã¦ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
                        workbook = writer.book
                        worksheet = writer.sheets['ç…§åˆçµæœ']
                        
                        # ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ«
                        header_font = Font(bold=True, color="FFFFFF")
                        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                        
                        for cell in worksheet[1]:
                            cell.font = header_font
                            cell.fill = header_fill
                    
                    excel_buffer.seek(0)
                    zip_file.writestr(corrected_name, excel_buffer.getvalue())
            
            zip_buffer.seek(0)
            st.download_button(
                label="ğŸ“¦ ä¿®æ­£ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=zip_buffer.getvalue(),
                file_name="JBAç…§åˆçµæœ_ä¿®æ­£ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«.zip",
                mime="application/zip"
            )
            
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            st.error("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    main()